% DDPM Image Generation
% Citations: 10799
@article{ddpm,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}

% Stable Diffusion original paper
% Citations: 5816
@inproceedings{stable_diffusion,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10684--10695},
  year={2022}
}

% GAN Text-to-image synthesis
% Citations: 3718
@inproceedings{reed2016generative,
  title={Generative adversarial text to image synthesis},
  author={Reed, Scott and Akata, Zeynep and Yan, Xinchen and Logeswaran, Lajanugen and Schiele, Bernt and Lee, Honglak},
  booktitle={International conference on machine learning},
  pages={1060--1069},
  year={2016},
  organization={PMLR}
}

% Original paper about diffusion models
% Citations: 3554
@inproceedings{diffusion_models,
  title={Deep unsupervised learning using nonequilibrium thermodynamics},
  author={Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya},
  booktitle={International conference on machine learning},
  pages={2256--2265},
  year={2015},
  organization={PMLR}
}

% Image synthesis
% Citations: 661
@inproceedings{shin2018medical,
  title={Medical image synthesis for data augmentation and anonymization using generative adversarial networks},
  author={Shin, Hoo-Chang and Tenenholtz, Neil A and Rogers, Jameson K and Schwarz, Christopher G and Senjem, Matthew L and Gunter, Jeffrey L and Andriole, Katherine P and Michalski, Mark},
  booktitle={Simulation and Synthesis in Medical Imaging: Third International Workshop, SASHIMI 2018, Held in Conjunction with MICCAI 2018, Granada, Spain, September 16, 2018, Proceedings 3},
  pages={1--11},
  year={2018},
  organization={Springer}
}

% GAN Image synthesis: VQ-GAN
% Citations: 207
@article{yu2021vector,
  title={Vector-quantized image modeling with improved vqgan},
  author={Yu, Jiahui and Li, Xin and Koh, Jing Yu and Zhang, Han and Pang, Ruoming and Qin, James and Ku, Alexander and Xu, Yuanzhong and Baldridge, Jason and Wu, Yonghui},
  journal={arXiv preprint arXiv:2110.04627},
  year={2021}
}

% Survey of Image Generation
% Citations: 197
@article{jiao2019survey,
  title={A survey on the new generation of deep learning in image processing},
  author={Jiao, Licheng and Zhao, Jin},
  journal={Ieee Access},
  volume={7},
  pages={172231--172263},
  year={2019},
  publisher={IEEE}
}

% Image synthesis survey
% Citations: 48
@inproceedings{tsirikoglou2020survey,
  title={A survey of image synthesis methods for visual machine learning},
  author={Tsirikoglou, Apostolia and Eilertsen, Gabriel and Unger, Jonas},
  booktitle={Computer Graphics Forum},
  volume={39},
  number={6},
  pages={426--451},
  year={2020},
  organization={Wiley Online Library}
}

% Comprehensive, good survey about GANs
% Citations: 48
@article{dash2023review,
  title={A review of Generative Adversarial Networks (GANs) and its applications in a wide variety of disciplines: From Medical to Remote Sensing},
  author={Dash, Ankan and Ye, Junyi and Wang, Guiling},
  journal={IEEE Access},
  year={2023},
  publisher={IEEE}
}

% DPM made slim
% Citations: 38
@inproceedings{yang2023diffusion,
  title={Diffusion probabilistic model made slim},
  author={Yang, Xingyi and Zhou, Daquan and Feng, Jiashi and Wang, Xinchao},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={22552--22562},
  year={2023}
}

% DPM Image Synthesis (KOALA)
% Citations: 1
% Source: https://huggingface.co/etri-vilab/koala-700m-llava-cap
@article{lee2023koala,
  title={KOALA: Self-attention matters in knowledge distillation of latent diffusion models for memory-efficient and fast image synthesis},
  author={Lee, Youngwan and Park, Kwanyong and Cho, Yoorhim and Lee, Yong-Ju and Hwang, Sung Ju},
  journal={arXiv preprint arXiv:2312.04005},
  year={2023}
}

% Stable Diffusion 3 Official Paper
% Citations: 0
% Source: https://stabilityai-public-packages.s3.us-west-2.amazonaws.com/Stable+Diffusion+3+Paper.pdf
% Website: https://stability.ai/news/stable-diffusion-3-research-paper

















% Vision Transformer
% Citations: 30781
@article{vision_transformer,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

% WGAN
% Citations: 15367
@inproceedings{arjovsky2017wasserstein,
  title={Wasserstein generative adversarial networks},
  author={Arjovsky, Martin and Chintala, Soumith and Bottou, L{\'e}on},
  booktitle={International conference on machine learning},
  pages={214--223},
  year={2017},
  organization={PMLR}
}

% OpenAI DALL-E paper
% Citations: 3329
@inproceedings{dalle,
  title={Zero-shot text-to-image generation},
  author={Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  booktitle={International conference on machine learning},
  pages={8821--8831},
  year={2021},
  organization={Pmlr}
}

% Score-based generative models (SGMs)
% Citations: 2209
@article{song2019generative,
  title={Generative modeling by estimating gradients of the data distribution},
  author={Song, Yang and Ermon, Stefano},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

% OpenAI improved learning objective of DDPM
% Citations: 1788
@inproceedings{openai_improved_ddpm,
  title={Improved denoising diffusion probabilistic models},
  author={Nichol, Alexander Quinn and Dhariwal, Prafulla},
  booktitle={International conference on machine learning},
  pages={8162--8171},
  year={2021},
  organization={PMLR}
}

% Stochastic differential equations (Score SDEs)
% Citations: 633
@article{karras2022elucidating,
  title={Elucidating the design space of diffusion-based generative models},
  author={Karras, Tero and Aittala, Miika and Aila, Timo and Laine, Samuli},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={26565--26577},
  year={2022}
}

% DPM Survey
% Citations: 543
@article{yang2023diffusion_survey,
  title={Diffusion models: A comprehensive survey of methods and applications},
  author={Yang, Ling and Zhang, Zhilong and Song, Yang and Hong, Shenda and Xu, Runsheng and Zhao, Yue and Zhang, Wentao and Cui, Bin and Yang, Ming-Hsuan},
  journal={ACM Computing Surveys},
  volume={56},
  number={4},
  pages={1--39},
  year={2023},
  publisher={ACM New York, NY, USA}
}

% DPM Survey
% Citations: 445
@article{croitoru2023diffusion,
  title={Diffusion models in vision: A survey},
  author={Croitoru, Florinel-Alin and Hondru, Vlad and Ionescu, Radu Tudor and Shah, Mubarak},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2023},
  publisher={IEEE}
}

% Explanation for VAEs
% Citations: 186
@article{girin2020dynamical,
  title={Dynamical variational autoencoders: A comprehensive review},
  author={Girin, Laurent and Leglaive, Simon and Bie, Xiaoyu and Diard, Julien and Hueber, Thomas and Alameda-Pineda, Xavier},
  journal={arXiv preprint arXiv:2008.12595},
  year={2020}
}

% Google paper explaining DPM
% Citations: 155
@article{luo2022understanding,
  title={Understanding diffusion models: A unified perspective},
  author={Luo, Calvin},
  journal={arXiv preprint arXiv:2208.11970},
  year={2022}
}

% Survey paper about DPMs
% Citations: 133
@article{cao2024survey,
  title={A survey on generative diffusion models},
  author={Cao, Hanqun and Tan, Cheng and Gao, Zhangyang and Xu, Yilun and Chen, Guangyong and Heng, Pheng-Ann and Li, Stan Z},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  year={2024},
  publisher={IEEE}
}

% AnimatedDiff
% Citations: 95
@article{guo2023animatediff,
  title={Animatediff: Animate your personalized text-to-image diffusion models without specific tuning},
  author={Guo, Yuwei and Yang, Ceyuan and Rao, Anyi and Wang, Yaohui and Qiao, Yu and Lin, Dahua and Dai, Bo},
  journal={arXiv preprint arXiv:2307.04725},
  year={2023}
}

% DDPMs Noise schedulers
% Citations: 63
@article{chen2023importance,
  title={On the importance of noise scheduling for diffusion models},
  author={Chen, Ting},
  journal={arXiv preprint arXiv:2301.10972},
  year={2023}
}

% VAE Survey
% Citations: 27
@article{asperti2021survey,
  title={A survey on variational autoencoders from a green AI perspective},
  author={Asperti, Andrea and Evangelista, Davide and Loli Piccolomini, Elena},
  journal={SN Computer Science},
  volume={2},
  number={4},
  pages={301},
  year={2021},
  publisher={Springer}
}

% Patches: Patch-based Object-centric Video Transformer (POVT)
% Citations: 2
@article{yan2022patch,
  title={Patch-based Object-centric Transformers for Efficient Video Generation},
  author={Yan, Wilson and Okumura, Ryo and James, Stephen and Abbeel, Pieter},
  journal={arXiv preprint arXiv:2206.04003},
  year={2022}
}

% Genie
% Citations: 0
@article{bruce2024genie,
  title={Genie: Generative Interactive Environments},
  author={Bruce, Jake and Dennis, Michael and Edwards, Ashley and Parker-Holder, Jack and Shi, Yuge and Hughes, Edward and Lai, Matthew and Mavalankar, Aditi and Steigerwald, Richie and Apps, Chris and others},
  journal={arXiv preprint arXiv:2402.15391},
  year={2024}
}


% Midjourney website
@misc{midjourney-website,
  title = {Midjourney website},
  url = {https://www.midjourney.com/home}
}

@misc{dk-divergence-math-explanation,
    title = {KL Divergence video explanation},
    url = {https://www.youtube.com/watch?v=9_eZHt2qJs4}
}









% Predict future images from video
% Citations: 2198
@article{mathieu2015deep,
  title={Deep multi-scale video prediction beyond mean square error},
  author={Mathieu, Michael and Couprie, Camille and LeCun, Yann},
  journal={arXiv preprint arXiv:1511.05440},
  year={2015}
}

% Video synthesis: vid2vid
% Citations: 1082
@article{wang2018video,
  title={Video-to-video synthesis},
  author={Wang, Ting-Chun and Liu, Ming-Yu and Zhu, Jun-Yan and Liu, Guilin and Tao, Andrew and Kautz, Jan and Catanzaro, Bryan},
  journal={arXiv preprint arXiv:1808.06601},
  year={2018}
}

% Video synthesis: TGAN (Temporal GAN)
% Citations: 622
@inproceedings{saito2017temporal,
  title={Temporal generative adversarial nets with singular value clipping},
  author={Saito, Masaki and Matsumoto, Eiichi and Saito, Shunta},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2830--2839},
  year={2017}
}

% Meta AI: text to video generation
% Citations: 544
@article{singer2022make,
  title={Make-a-video: Text-to-video generation without text-video data},
  author={Singer, Uriel and Polyak, Adam and Hayes, Thomas and Yin, Xi and An, Jie and Zhang, Songyang and Hu, Qiyuan and Yang, Harry and Ashual, Oron and Gafni, Oran and others},
  journal={arXiv preprint arXiv:2209.14792},
  year={2022}
}

% Video synthesis
% Citations: 223
@inproceedings{video_generation_from_text,
  title={Video generation from text},
  author={Li, Yitong and Min, Martin and Shen, Dinghan and Carlson, David and Carin, Lawrence},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  number={1},
  year={2018}
}

% GAN Video synthesis: MoCoGAN-HD
% Citations: 138
@article{mocogan_hd,
  title={A good image generator is what you need for high-resolution video synthesis},
  author={Tian, Yu and Ren, Jian and Chai, Menglei and Olszewski, Kyle and Peng, Xi and Metaxas, Dimitris N and Tulyakov, Sergey},
  journal={arXiv preprint arXiv:2104.15069},
  year={2021}
}

% DVD-GAN
% Citations: 192
% Source: https://paperswithcode.com/method/dvd-gan
@article{clark2019adversarial,
  title={Adversarial video generation on complex datasets},
  author={Clark, Aidan and Donahue, Jeff and Simonyan, Karen},
  journal={arXiv preprint arXiv:1907.06571},
  year={2019}
}

% DPM Video survey
% Citations: 132
@article{yang2023diffusion_video,
  title={Diffusion probabilistic modeling for video generation},
  author={Yang, Ruihan and Srivastava, Prakhar and Mandt, Stephan},
  journal={Entropy},
  volume={25},
  number={10},
  pages={1469},
  year={2023},
  publisher={MDPI}
}

% GAN Video synthesis: TFGAN
% Citations: 92
@inproceedings{balaji2019conditional,
  title={Conditional GAN with Discriminative Filter Generation for Text-to-Video Synthesis.},
  author={Balaji, Yogesh and Min, Martin Renqiang and Bai, Bing and Chellappa, Rama and Graf, Hans Peter},
  booktitle={IJCAI},
  volume={1},
  number={2019},
  pages={2},
  year={2019}
}

% GAN Video generation survey
% Citations: 72
@article{aldausari2022video,
  title={Video generative adversarial networks: a review},
  author={Aldausari, Nuha and Sowmya, Arcot and Marcus, Nadine and Mohammadi, Gelareh},
  journal={ACM Computing Surveys (CSUR)},
  volume={55},
  number={2},
  pages={1--25},
  year={2022},
  publisher={ACM New York, NY}
}

% DPM Video synthesis: IDF-Video
% Citations: 13
@article{gu2023reuse,
  title={Reuse and diffuse: Iterative denoising for text-to-video generation},
  author={Gu, Jiaxi and Wang, Shicong and Zhao, Haoyu and Lu, Tianyi and Zhang, Xing and Wu, Zuxuan and Xu, Songcen and Zhang, Wei and Jiang, Yu-Gang and Xu, Hang},
  journal={arXiv preprint arXiv:2309.03549},
  year={2023}
}






% Google paper: Video synthesis using DPM
% Paper: https://openreview.net/pdf?id=BBelR2NdDZ5











% VQGAN
% Citations: 1984
@inproceedings{vqgan,
  title={Taming transformers for high-resolution image synthesis},
  author={Esser, Patrick and Rombach, Robin and Ommer, Bjorn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={12873--12883},
  year={2021},
}

% Imagen
% Citations: 3837
@article{imagen,
  title={Photorealistic text-to-image diffusion models with deep language understanding},
  author={Saharia, Chitwan and Chan, William and Saxena, Saurabh and Li, Lala and Whang, Jay and Denton, Emily L and Ghasemipour, Kamyar and Gontijo Lopes, Raphael and Karagol Ayan, Burcu and Salimans, Tim and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={36479--36494},
  year={2022}
}

% Video-LDM
% Citations: 471
@inproceedings{video_ldm,
  title={Align your latents: High-resolution video synthesis with latent diffusion models},
  author={Blattmann, Andreas and Rombach, Robin and Ling, Huan and Dockhorn, Tim and Kim, Seung Wook and Fidler, Sanja and Kreis, Karsten},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={22563--22575},
  year={2023}
}

% Stable Video Diffusion by StabilityAI
% Citations: 199
@article{stable_video_diffusion,
  title={Stable video diffusion: Scaling latent video diffusion models to large datasets},
  author={Blattmann, Andreas and Dockhorn, Tim and Kulal, Sumith and Mendelevitch, Daniel and Kilian, Maciej and Lorenz, Dominik and Levi, Yam and English, Zion and Voleti, Vikram and Letts, Adam and others},
  journal={arXiv preprint arXiv:2311.15127},
  year={2023}
}

% Make-a-Video
% Citations: 1004
@article{make_a_video,
  title={Make-a-video: Text-to-video generation without text-video data},
  author={Singer, Uriel and Polyak, Adam and Hayes, Thomas and Yin, Xi and An, Jie and Zhang, Songyang and Hu, Qiyuan and Yang, Harry and Ashual, Oron and Gafni, Oran and others},
  journal={arXiv preprint arXiv:2209.14792},
  year={2022}
}

% Sora website
@misc{sora_website,
  title        = {Sora by OpenAI website},
  year         = {2024},
  url = {https://openai.com/index/sora}
}

% Transformers
% Citations: 123714
@article{transformer,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

% VQ-VAE
% Citations: 3886
@article{vqvae,
  title={Neural discrete representation learning},
  author={Van Den Oord, Aaron and Vinyals, Oriol and others},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

% GAN
% Citations: 69508
@article{gan,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

% Autoencoders.
% "According to the history provided in Schmidhuber, "Deep learning in neural networks: an overview," Neural Networks (2015), auto-encoders were proposed as a method for unsupervised pre-training in Ballard, "Modular learning in neural networks," Proceedings AAAI (1987)."
% Citations: 22169
@article{autoencoder,
  title={Deep learning in neural networks: An overview},
  author={Schmidhuber, J{\"u}rgen},
  journal={Neural networks},
  volume={61},
  pages={85--117},
  year={2015},
  publisher={Elsevier}
}

% Original 1987 introduction to Autoencoder architecture
% Citations: 595
@inproceedings{autoencoder2,
  title={Modular learning in neural networks},
  author={Ballard, Dana H},
  booktitle={Proceedings of the sixth National conference on Artificial intelligence-Volume 1},
  pages={279--284},
  year={1987}
}

% VAE
% Citations: 33653
@article{vae,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

% CNN introduction
% Citations:  80761
@article{cnn,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group UK London}
}

% VAE + CNN example paper
% Citations: 
@article{vae_cnn_example,
  title={Convolutional variational autoencoder-based feature learning for automatic tea clone recognition},
  author={Zilvan, Vicky and Ramdan, Ade and Heryana, Ana and Krisnandi, Dikdik and Suryawati, Endang and Yuwana, R Sandra and Kusumo, R Budiarianto S and Pardede, Hilman F},
  journal={Journal of King Saud University-Computer and Information Sciences},
  volume={34},
  number={6},
  pages={3332--3342},
  year={2022},
  publisher={Elsevier}
}

@misc{ae_vs_vae,
  title        = {AE v.s. VAE figure source},
  url = {https://vitalflux.com/autoencoder-vs-variational-autoencoder-vae-difference/}
}

@misc{vq_visualization_website,
  title = {Vector quantization visualization, website source},
  url = {https://speechprocessingbook.aalto.fi/Modelling/Vector_quantization_VQ.html}
}

% Autoencoder original paper which wasn't used in machine learning until 2010s
% Citations: 28167
@article{autoencoder_original_paper_1986,
  title={Learning internal representations by error propagation, parallel distributed processing, explorations in the microstructure of cognition, ed. de rumelhart and j. mcclelland. vol. 1. 1986},
  author={Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J},
  journal={Biometrika},
  volume={71},
  number={599-607},
  pages={6},
  year={1986}
}

% Autoencoder paper from 2006 that introduced dimensionality reduction
% Citations: 22963
@article{autoencoder_2006_paper,
  title={Reducing the dimensionality of data with neural networks},
  author={Hinton, Geoffrey E and Salakhutdinov, Ruslan R},
  journal={science},
  volume={313},
  number={5786},
  pages={504--507},
  year={2006},
  publisher={American Association for the Advancement of Science}
}

% Very interesting read. Explains why the round function is not differentiable, which is important for the VQ-VAE model, since in VQ we 'round' embeddings to nearest codebook vectors.
@misc{why_round_function_is_not_differentiable,
  title = {Why the round function is not differentiable},
  url = {https://ai.stackexchange.com/questions/26770/in-vq-vae-code-what-does-this-line-of-code-signify}
}

% GAN mode collapse image source
@misc{gan_mode_collapse_image_source,
  title = {GAN mode-collapse image source},
  url = {https://pub.towardsai.net/gan-mode-collapse-explanation-fa5f9124ee73}
}

% The paper that introduced the VGG16 architecture (in use in VQGAN paper)
% Citations: 125554
@article{vgg16,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}

% Streight Through Estimator (STE) paper
% Citations: 3017
@article{ste,
  title={Estimating or propagating gradients through stochastic neurons for conditional computation},
  author={Bengio, Yoshua and L{\'e}onard, Nicholas and Courville, Aaron},
  journal={arXiv preprint arXiv:1308.3432},
  year={2013}
}

% minGPT or GPT-2 paper
% Citations: 11992
@article{mingpt,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

% PixelCNN
% Citations: 2746
@article{pixelcnn,
  title={Conditional image generation with pixelcnn decoders},
  author={Van den Oord, Aaron and Kalchbrenner, Nal and Espeholt, Lasse and Vinyals, Oriol and Graves, Alex and others},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

% FID score
% Citations: 12474
@article{fid_score,
  title={Gans trained by a two time-scale update rule converge to a local nash equilibrium},
  author={Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

% Inception Score (IS)
% Citations: 10394
@article{is_score,
  title={Improved techniques for training gans},
  author={Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

% InfoGAN
% Citations: 5346
@article{infogan,
  title={Infogan: Interpretable representation learning by information maximizing generative adversarial nets},
  author={Chen, Xi and Duan, Yan and Houthooft, Rein and Schulman, John and Sutskever, Ilya and Abbeel, Pieter},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

% StyleGAN
% Citations: 11245
@inproceedings{stylegan,
  title={A style-based generator architecture for generative adversarial networks},
  author={Karras, Tero and Laine, Samuli and Aila, Timo},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={4401--4410},
  year={2019}
}

% CycleGAN
% Citations: 23308
@inproceedings{cyclegan,
  title={Unpaired image-to-image translation using cycle-consistent adversarial networks},
  author={Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2223--2232},
  year={2017}
}

% Conditional GAN (cGAN)
% Citations: 13302
@article{cgan,
  title={Conditional generative adversarial nets},
  author={Mirza, Mehdi and Osindero, Simon},
  journal={arXiv preprint arXiv:1411.1784},
  year={2014}
}

% Inception V3 model paper
% Citations: 34112
@inproceedings{inception_v3_model,
  title={Rethinking the inception architecture for computer vision},
  author={Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2818--2826},
  year={2016}
}

% GAN architecture figure paper source
% Citations: 46
@article{gan_architecture_figure_paper,
  title={Data-efficient domain adaptation for semantic segmentation of aerial imagery using generative adversarial networks},
  author={Benjdira, Bilel and Ammar, Adel and Koubaa, Anis and Ouni, Kais},
  journal={Applied Sciences},
  volume={10},
  number={3},
  pages={1092},
  year={2020},
  publisher={MDPI}
}

% OpenAI paper shows diffusion models beat GANs
% Citations: 5508
@article{openai_diffusion_beats_gans,
  title={Diffusion models beat gans on image synthesis},
  author={Dhariwal, Prafulla and Nichol, Alexander},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={8780--8794},
  year={2021}
}

% Classifier-free diffusion guidance
% Citations: 2455
@article{classifier_free_guidance,
  title={Classifier-free diffusion guidance},
  author={Ho, Jonathan and Salimans, Tim},
  journal={arXiv preprint arXiv:2207.12598},
  year={2022}
}

% CLIP by OpenAI
% Citations: 20909
@inproceedings{openai_clip,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

% ResNet paper, 2015
% Citations: 234790
@inproceedings{resnet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

% Continous Bag of Words / Word2Vec
% Citations: 43519
@article{cbow_word2vec,
  title={Efficient estimation of word representations in vector space},
  author={Mikolov, Tomas},
  journal={arXiv preprint arXiv:1301.3781},
  year={2013}
}

% Perceptual loss
% Citations: 10194
@inproceedings{perceptual_loss,
  title={The unreasonable effectiveness of deep features as a perceptual metric},
  author={Zhang, Richard and Isola, Phillip and Efros, Alexei A and Shechtman, Eli and Wang, Oliver},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={586--595},
  year={2018}
}

% Perceptual loss in diffusion models, by ByteDance
% Citations: 6
@article{perceptual_loss_in_diffusion,
  title={Diffusion Model with Perceptual Loss},
  author={Lin, Shanchuan and Yang, Xiao},
  journal={arXiv preprint arXiv:2401.00110},
  year={2023}
}

% U-Net
% Citations: 92790
@inproceedings{unet,
  title={U-net: Convolutional networks for biomedical image segmentation},
  author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  booktitle={Medical image computing and computer-assisted intervention--MICCAI 2015: 18th international conference, Munich, Germany, October 5-9, 2015, proceedings, part III 18},
  pages={234--241},
  year={2015},
  organization={Springer}
}

% DDIM Sampler
% Citations: 4585
@article{ddim,
  title={Denoising diffusion implicit models},
  author={Song, Jiaming and Meng, Chenlin and Ermon, Stefano},
  journal={arXiv preprint arXiv:2010.02502},
  year={2020}
}

% BERT Tokenizer
% Citations: 112475
@article{bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

% Understanding deep learning book, 2024
% Citations: 141
@book{understanding_deep_learning_book_2024,
  title={Understanding deep learning},
  author={Prince, Simon JD},
  year={2023},
  publisher={MIT press}
}

% Exploding and vanishing gradients problem
% Citations: 12728
@article{exploding_vanishing_gradients,
  title={Learning long-term dependencies with gradient descent is difficult},
  author={Bengio, Yoshua and Simard, Patrice and Frasconi, Paolo},
  journal={IEEE transactions on neural networks},
  volume={5},
  number={2},
  pages={157--166},
  year={1994},
  publisher={IEEE}
}

% Score-based generative modeling
% Citations: 4402
@article{score_based_generative_modeling,
  title={Score-based generative modeling through stochastic differential equations},
  author={Song, Yang and Sohl-Dickstein, Jascha and Kingma, Diederik P and Kumar, Abhishek and Ermon, Stefano and Poole, Ben},
  journal={arXiv preprint arXiv:2011.13456},
  year={2020}
}

% VQ-GAN+CLIP
% Citations: 371
@inproceedings{vqgan_clip,
  title={Vqgan-clip: Open domain image generation and editing with natural language guidance},
  author={Crowson, Katherine and Biderman, Stella and Kornis, Daniel and Stander, Dashiell and Hallahan, Eric and Castricato, Louis and Raff, Edward},
  booktitle={European Conference on Computer Vision},
  pages={88--105},
  year={2022},
  organization={Springer}
}

% GLIDE
% Citations: 2788
@article{glide,
  title={Glide: Towards photorealistic image generation and editing with text-guided diffusion models},
  author={Nichol, Alex and Dhariwal, Prafulla and Ramesh, Aditya and Shyam, Pranav and Mishkin, Pamela and McGrew, Bob and Sutskever, Ilya and Chen, Mark},
  journal={arXiv preprint arXiv:2112.10741},
  year={2021}
}

% DALL-E 2 paper
% Citations: 6089
@article{dalle_2,
  title={Hierarchical text-conditional image generation with clip latents},
  author={Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  journal={arXiv preprint arXiv:2204.06125},
  volume={1},
  number={2},
  pages={3},
  year={2022}
}

% T5 model
% Citations: 18087
@article{t5_model,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={Journal of machine learning research},
  volume={21},
  number={140},
  pages={1--67},
  year={2020}
}

% Common Crawl Project
@misc{common_crawl_project,
  title = {Common Crawl website},
  url = {https://commoncrawl.org/}
}

% Larger datasets -> Better performance
% Citations: 722
@article{hestness2017deep,
  title={Deep learning scaling is predictable, empirically},
  author={Hestness, Joel and Narang, Sharan and Ardalani, Newsha and Diamos, Gregory and Jun, Heewoo and Kianinejad, Hassan and Patwary, Md Mostofa Ali and Yang, Yang and Zhou, Yanqi},
  journal={arXiv preprint arXiv:1712.00409},
  year={2017}
}

% Larger datasets -> Better performance
% Citations: 1422
@article{jozefowicz2016exploring,
  title={Exploring the limits of language modeling},
  author={Jozefowicz, Rafal and Vinyals, Oriol and Schuster, Mike and Shazeer, Noam and Wu, Yonghui},
  journal={arXiv preprint arXiv:1602.02410},
  year={2016}
}

% Larger datasets -> Better performance
% Citations: 13378
@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

% GPT paper
% Citations: 32436
@article{gpt,
  title={Language models are few-shot learners},
  author={Brown, Tom B},
  journal={arXiv preprint arXiv:2005.14165},
  year={2020}
}

% Another GPT paper - introducted generative pre-training concept
% Citations: 10939
@article{gpt_another,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec},
  year={2018}
}

% Cascaded diffusion models by Google Research, Cascaded DPMs
% Citations: 950
@article{cascaded_diffusion_models,
  title={Cascaded diffusion models for high fidelity image generation},
  author={Ho, Jonathan and Saharia, Chitwan and Chan, William and Fleet, David J and Norouzi, Mohammad and Salimans, Tim},
  journal={Journal of Machine Learning Research},
  volume={23},
  number={47},
  pages={1--33},
  year={2022}
}

% VQ-VAE-2
% Citations: 1766
@article{vqvae2,
  title={Generating diverse high-fidelity images with vq-vae-2},
  author={Razavi, Ali and Van den Oord, Aaron and Vinyals, Oriol},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

% BigGAN-deep / BigGAN
% Citations: 6021
@article{biggan_deep,
  title={Large Scale GAN Training for High Fidelity Natural Image Synthesis},
  author={Brock, Andrew},
  journal={arXiv preprint arXiv:1809.11096},
  year={2018}
}

% SR3 paper (super-resolution in cascading diffusion models)
% Citations: 1510
@article{sr3,
  title={Image super-resolution via iterative refinement},
  author={Saharia, Chitwan and Ho, Jonathan and Chan, William and Salimans, Tim and Fleet, David J and Norouzi, Mohammad},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={45},
  number={4},
  pages={4713--4726},
  year={2022},
  publisher={IEEE}
}

% Microsoft COCO dataset
% Citations: 50786
@inproceedings{coco_dataset,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13},
  pages={740--755},
  year={2014},
  organization={Springer}
}

% Perceptual quality and GAN evaluation
% Citations: 283
@inproceedings{perceptual_quality,
  title={On aliased resizing and surprising subtleties in gan evaluation},
  author={Parmar, Gaurav and Zhang, Richard and Zhu, Jun-Yan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11410--11420},
  year={2022}
}

% Video generation GAN based adversarial learning
% Citations: 220
@article{chu2020learning,
  title={Learning temporal coherence via self-supervision for GAN-based video generation},
  author={Chu, Mengyu and Xie, You and Mayer, Jonas and Leal-Taix{\'e}, Laura and Thuerey, Nils},
  journal={ACM Transactions on Graphics (TOG)},
  volume={39},
  number={4},
  pages={75--1},
  year={2020},
  publisher={ACM New York, NY, USA}
}

% Swish activation function
@article{ramachandran2017swish,
  title={Swish: A Self-Gated Activation Function},
  author={Ramachandran, Prajit and Zoph, Barret and Le, Quoc V},
  journal={arXiv preprint arXiv:1710.05941},
  year={2017}
}

% Layer normalization
% Citations: 12755
@article{layernorm,
  title={Layer normalization},
  author={Ba, Jimmy Lei},
  journal={arXiv preprint arXiv:1607.06450},
  year={2016}
}

% Batch normalization
% Citations: 58010
@article{batchnorm,
  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  author={Ioffe, Sergey},
  journal={arXiv preprint arXiv:1502.03167},
  year={2015}
}

% VideoGAN: Video generation with GAN
% Citations: 1773
@article{video_gan,
  title={Generating videos with scene dynamics},
  author={Vondrick, Carl and Pirsiavash, Hamed and Torralba, Antonio},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

% Group normalization, Batch normalization, Layer normalization
% Citations: 4322
@inproceedings{wu2018group,
  title={Group normalization},
  author={Wu, Yuxin and He, Kaiming},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={3--19},
  year={2018}
}

% Video generation survey
% Citations: 5
@article{long_video_survey,
  title={A survey on long video generation: Challenges, methods, and prospects},
  author={Li, Chengxuan and Huang, Di and Lu, Zeyu and Xiao, Yang and Pei, Qingqi and Bai, Lei},
  journal={arXiv preprint arXiv:2403.16407},
  year={2024}
}

% Sequence generation with RNN, 2013, old
% Citations: 5446
@article{graves2013generating,
  title={Generating sequences with recurrent neural networks},
  author={Graves, Alex},
  journal={arXiv preprint arXiv:1308.0850},
  year={2013}
}

% Nuwa-xl video generation, 2023
% Citations: 70
@article{nuwa_xl,
  title={Nuwa-xl: Diffusion over diffusion for extremely long video generation},
  author={Yin, Shengming and Wu, Chenfei and Yang, Huan and Wang, Jianfeng and Wang, Xiaodong and Ni, Minheng and Yang, Zhengyuan and Li, Linjie and Liu, Shuguang and Yang, Fan and others},
  journal={arXiv preprint arXiv:2303.12346},
  year={2023}
}

% 2012: Uses 3D VQGAN to generate videos
% Citations: 177
@inproceedings{ge2022long,
  title={Long video generation with time-agnostic vqgan and time-sensitive transformer},
  author={Ge, Songwei and Hayes, Thomas and Yang, Harry and Yin, Xi and Pang, Guan and Jacobs, David and Huang, Jia-Bin and Parikh, Devi},
  booktitle={European Conference on Computer Vision},
  pages={102--118},
  year={2022},
  organization={Springer}
}

% VideoGPT
% Citations: 373
@article{videogpt,
  title={Videogpt: Video generation using vq-vae and transformers},
  author={Yan, Wilson and Zhang, Yunzhi and Abbeel, Pieter and Srinivas, Aravind},
  journal={arXiv preprint arXiv:2104.10157},
  year={2021}
}

% 2022: low-resolution video generation then using super-resolution, Long Video GAN (LVG), Mountain bike dataset
% Citations: 93
@article{brooks2022generating,
  title={Generating long videos of dynamic scenes},
  author={Brooks, Tim and Hellsten, Janne and Aittala, Miika and Wang, Ting-Chun and Aila, Timo and Lehtinen, Jaakko and Liu, Ming-Yu and Efros, Alexei and Karras, Tero},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={31769--31781},
  year={2022}
}

% StyleGAN3
% Citations: 1578
@article{stylegan3,
  title={Alias-free generative adversarial networks},
  author={Karras, Tero and Aittala, Miika and Laine, Samuli and H{\"a}rk{\"o}nen, Erik and Hellsten, Janne and Lehtinen, Jaakko and Aila, Timo},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={852--863},
  year={2021}
}

% CogVideo
% Citations: 348
@article{cogvideo,
  title={Cogvideo: Large-scale pretraining for text-to-video generation via transformers},
  author={Hong, Wenyi and Ding, Ming and Zheng, Wendi and Liu, Xinghan and Tang, Jie},
  journal={arXiv preprint arXiv:2205.15868},
  year={2022}
}

% Compressing videos to 3D latent space
% Citations: 44
@inproceedings{zeng2024make,
  title={Make pixels dance: High-dynamic video generation},
  author={Zeng, Yan and Wei, Guoqiang and Zheng, Jiani and Zou, Jiaxin and Wei, Yang and Zhang, Yuchen and Li, Hang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8850--8860},
  year={2024}
}

% Compressing videos to 3D latent space
% Citations: 30
@article{gu2023reuse,
  title={Reuse and diffuse: Iterative denoising for text-to-video generation},
  author={Gu, Jiaxi and Wang, Shicong and Zhao, Haoyu and Lu, Tianyi and Zhang, Xing and Wu, Zuxuan and Xu, Songcen and Zhang, Wei and Jiang, Yu-Gang and Xu, Hang},
  journal={arXiv preprint arXiv:2309.03549},
  year={2023}
}

% 2023: Projected Latent Video Diffusion Model (PVDM)
% Citations: 128
@inproceedings{pvdm,
  title={Video probabilistic diffusion models in projected latent space},
  author={Yu, Sihyun and Sohn, Kihyuk and Kim, Subin and Shin, Jinwoo},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={18456--18466},
  year={2023}
}

% 2022: Nuwa-infinity: convert video frames to patches with positional data
% Citations: 32
@article{nuwa_infinity,
  title={Nuwa-infinity: Autoregressive over autoregressive generation for infinite visual synthesis},
  author={Wu, Chenfei and Liang, Jian and Hu, Xiaowei and Gan, Zhe and Wang, Jianfeng and Wang, Lijuan and Liu, Zicheng and Fang, Yuejian and Duan, Nan},
  journal={arXiv preprint arXiv:2207.09814},
  year={2022}
}

% Transframer: Convert video frames into latent tokens with VQGAN
% Citations: 35
@article{transframer,
  title={Transframer: Arbitrary frame prediction with generative models},
  author={Nash, Charlie and Carreira, Joao and Walker, Jacob and Barr, Iain and Jaegle, Andrew and Malinowski, Mateusz and Battaglia, Peter},
  journal={arXiv preprint arXiv:2203.09494},
  year={2022}
}

% 2019: FVD evaluation metric for videos by Google Research
% Citations: 112
@article{fvd,
  title={FVD: A new metric for video generation},
  author={Unterthiner, Thomas and van Steenkiste, Sjoerd and Kurach, Karol and Marinier, Rapha{\"e}l and Michalski, Marcin and Gelly, Sylvain},
  year={2019}
}

% 2014: First time use of 3D ConvNets for video data by Facebook AI
% Citations: 10472
@inproceedings{tran2015learning,
  title={Learning spatiotemporal features with 3d convolutional networks},
  author={Tran, Du and Bourdev, Lubomir and Fergus, Rob and Torresani, Lorenzo and Paluri, Manohar},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={4489--4497},
  year={2015}
}

% 2018: Facebook AIL Review of spatiotemporal convolution
% Citations: 3627
@inproceedings{tran2018closer,
  title={A closer look at spatiotemporal convolutions for action recognition},
  author={Tran, Du and Wang, Heng and Torresani, Lorenzo and Ray, Jamie and LeCun, Yann and Paluri, Manohar},
  booktitle={Proceedings of the IEEE conference on Computer Vision and Pattern Recognition},
  pages={6450--6459},
  year={2018}
}

% 2012: AlexNet paper breakthrough in image classification
% Citations: 134518
@article{alexnet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={Advances in neural information processing systems},
  volume={25},
  year={2012}
}

% 2020: Image-GPT by OpenAI paper, use transformer to predict pixels directly
% Citations: 1708
@inproceedings{imagegpt,
  title={Generative pretraining from pixels},
  author={Chen, Mark and Radford, Alec and Child, Rewon and Wu, Jeffrey and Jun, Heewoo and Luan, David and Sutskever, Ilya},
  booktitle={International conference on machine learning},
  pages={1691--1703},
  year={2020},
  organization={PMLR}
}

% Imagen Video
% Citations: 1163
@article{imagen_video,
  title={Imagen video: High definition video generation with diffusion models},
  author={Ho, Jonathan and Chan, William and Saharia, Chitwan and Whang, Jay and Gao, Ruiqi and Gritsenko, Alexey and Kingma, Diederik P and Poole, Ben and Norouzi, Mohammad and Fleet, David J and others},
  journal={arXiv preprint arXiv:2210.02303},
  year={2022}
}

% Video U-Net architecture
% Citations: 1130
@article{video_diffusion_models,
  title={Video diffusion models},
  author={Ho, Jonathan and Salimans, Tim and Gritsenko, Alexey and Chan, William and Norouzi, Mohammad and Fleet, David J},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={8633--8646},
  year={2022}
}

% Axial attention
% Citations: 587
@article{axial_attention,
  title={Axial attention in multidimensional transformers},
  author={Ho, Jonathan and Kalchbrenner, Nal and Weissenborn, Dirk and Salimans, Tim},
  journal={arXiv preprint arXiv:1912.12180},
  year={2019}
}

% Stochastic differential equations figure 
% Citations: 4851
@article{song2020score,
  title={Score-based generative modeling through stochastic differential equations},
  author={Song, Yang and Sohl-Dickstein, Jascha and Kingma, Diederik P and Kumar, Abhishek and Ermon, Stefano and Poole, Ben},
  journal={arXiv preprint arXiv:2011.13456},
  year={2020}
}

% 2017: Wasserstein GAN paper - Discriminator loss is added to the reconstruction score of VAE in Video-LDM
% Citations: 24554
@inproceedings{isola2017image,
  title={Image-to-image translation with conditional adversarial networks},
  author={Isola, Phillip and Zhu, Jun-Yan and Zhou, Tinghui and Efros, Alexei A},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1125--1134},
  year={2017}
}

% Einops
% Citations: 107
@inproceedings{einops,
  title={Einops: Clear and reliable tensor manipulations with einstein-like notation},
  author={Rogozhnikov, Alex},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

% Generative AI survey paper
% Citations: 16
@article{zhou2024survey,
  title={A survey on generative ai and llm for video generation, understanding, and streaming},
  author={Zhou, Pengyuan and Wang, Lin and Liu, Zhi and Hao, Yanbin and Hui, Pan and Tarkoma, Sasu and Kangasharju, Jussi},
  journal={arXiv preprint arXiv:2404.16038},
  year={2024}
}

% Text-to-Video survey paper, Sora focused
% Citations: 4
@article{sun2024sora,
  title={From Sora What We Can See: A Survey of Text-to-Video Generation},
  author={Sun, Rui and Zhang, Yumin and Shah, Tejal and Sun, Jiahao and Zhang, Shuoying and Li, Wenqi and Duan, Haoran and Wei, Bo and Ranjan, Rajiv},
  journal={arXiv preprint arXiv:2405.10674},
  year={2024}
}

% MagicVideo
% Citations: 278
@article{magic_video,
  title={Magicvideo: Efficient video generation with latent diffusion models},
  author={Zhou, Daquan and Wang, Weimin and Yan, Hanshu and Lv, Weiwei and Zhu, Yizhe and Feng, Jiashi},
  journal={arXiv preprint arXiv:2211.11018},
  year={2022}
}

% Use LSTM to capture temporal dynamics
% Citations:  1798
@inproceedings{venugopalan2015sequence,
  title={Sequence to sequence-video to text},
  author={Venugopalan, Subhashini and Rohrbach, Marcus and Donahue, Jeffrey and Mooney, Raymond and Darrell, Trevor and Saenko, Kate},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={4534--4542},
  year={2015}
}

% Diffusion Transformers
% Citations: 1005
@inproceedings{diffusion_transformer,
  title={Scalable diffusion models with transformers},
  author={Peebles, William and Xie, Saining},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4195--4205},
  year={2023}
}

% Spatial and temporal self attention good figure (STA, TSA)
% Citations: 253
@inproceedings{plizzari2021spatial,
  title={Spatial temporal transformer network for skeleton-based action recognition},
  author={Plizzari, Chiara and Cannici, Marco and Matteucci, Matteo},
  booktitle={Pattern recognition. ICPR international workshops and challenges: virtual event, January 10--15, 2021, Proceedings, Part III},
  pages={694--701},
  year={2021},
  organization={Springer}
}

% WebVid-10M dataset
% Citations: 1008
@inproceedings{webvid_10m,
  title={Frozen in time: A joint video and image encoder for end-to-end retrieval},
  author={Bain, Max and Nagrani, Arsha and Varol, G{\"u}l and Zisserman, Andrew},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={1728--1738},
  year={2021}
}

% StyleVideoGAN
% Citations: 45
@article{style_video_gan,
  title={Stylevideogan: A temporal generative model using a pretrained stylegan},
  author={Fox, Gereon and Tewari, Ayush and Elgharib, Mohamed and Theobalt, Christian},
  journal={arXiv preprint arXiv:2107.07224},
  year={2021}
}

% EasyAnimate, July 2024, Slice VAE + DiT video generator
% Citations: 6
@article{easyanimate,
  title={EasyAnimate: A High-Performance Long Video Generation Method based on Transformer Architecture},
  author={Xu, Jiaqi and Zou, Xinyi and Huang, Kunzhe and Chen, Yunkuo and Liu, Bo and Cheng, MengLi and Shi, Xing and Huang, Jun},
  journal={arXiv preprint arXiv:2405.18991},
  year={2024}
}

% v-prediction in Imagen-Video
% Citations: 950
@article{v_prediction,
  title={Progressive distillation for fast sampling of diffusion models},
  author={Salimans, Tim and Ho, Jonathan},
  journal={arXiv preprint arXiv:2202.00512},
  year={2022}
}

% Use stochastic sampler with distilled diffusion model
% Citations: 365
@inproceedings{meng2023distillation,
  title={On distillation of guided diffusion models},
  author={Meng, Chenlin and Rombach, Robin and Gao, Ruiqi and Kingma, Diederik and Ermon, Stefano and Ho, Jonathan and Salimans, Tim},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14297--14306},
  year={2023}
}

% Laion-400m dataset
% Citations: 1170
@article{laion_400m,
  title={Laion-400m: Open dataset of clip-filtered 400 million image-text pairs},
  author={Schuhmann, Christoph and Vencu, Richard and Beaumont, Romain and Kaczmarczyk, Robert and Mullis, Clayton and Katta, Aarush and Coombes, Theo and Jitsev, Jenia and Komatsuzaki, Aran},
  journal={arXiv preprint arXiv:2111.02114},
  year={2021}
}

% Time-step incorporated into diffusion backbone in "on distillation..." paper
% Citations: 945
@article{kingma2021variational,
  title={Variational diffusion models},
  author={Kingma, Diederik and Salimans, Tim and Poole, Ben and Ho, Jonathan},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={21696--21707},
  year={2021}
}

% Because 3D conv is expensive, here they first do spatial computations and only then depth computation on the temporal axis
% Citations: 20114
@inproceedings{chollet2017xception,
  title={Xception: Deep learning with depthwise separable convolutions},
  author={Chollet, Francois},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1251--1258},
  year={2017}
}

% Laion-5b image-text dataset
% Citations: 2688
@article{laion_5b,
  title={Laion-5b: An open large-scale dataset for training next generation image-text models},
  author={Schuhmann, Christoph and Beaumont, Romain and Vencu, Richard and Gordon, Cade and Wightman, Ross and Cherti, Mehdi and Coombes, Theo and Katta, Aarush and Mullis, Clayton and Wortsman, Mitchell and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={25278--25294},
  year={2022}
}

% MSR-VTT video captions dataset by Microsoft
% Citations: 2178
@inproceedings{msr_vtt,
  title={Msr-vtt: A large video description dataset for bridging video and language},
  author={Xu, Jun and Mei, Tao and Yao, Ting and Rui, Yong},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={5288--5296},
  year={2016}
}

% HD-VILA-100M dataset
% Citations: 168
@inproceedings{hd_vila_100m,
  title={Advancing high-resolution video-language representation with large-scale video transcriptions},
  author={Xue, Hongwei and Hang, Tiankai and Zeng, Yanhong and Sun, Yuchong and Liu, Bei and Yang, Huan and Fu, Jianlong and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5036--5045},
  year={2022}
}

% UCF-101 dataset
% Citations: 7015
@article{ucf_101,
  title={UCF101: A dataset of 101 human actions classes from videos in the wild},
  author={Soomro, K},
  journal={arXiv preprint arXiv:1212.0402},
  year={2012}
}

% FILM - Frame interpolation model
% Citations: 158
@inproceedings{film,
  title={Film: Frame interpolation for large motion},
  author={Reda, Fitsum and Kontkanen, Janne and Tabellion, Eric and Sun, Deqing and Pantofaru, Caroline and Curless, Brian},
  booktitle={European Conference on Computer Vision},
  pages={250--266},
  year={2022},
  organization={Springer}
}