% Original GAN paper
% Citations: 65266
@article{goodfellow2014generative,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

% cGAN - Conditional GAN
% Citations: 12258
@article{mirza2014conditional,
  title={Conditional generative adversarial nets},
  author={Mirza, Mehdi and Osindero, Simon},
  journal={arXiv preprint arXiv:1411.1784},
  year={2014}
}

% DDPM Image Generation
% Citations: 7133
@article{ddpm,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}

% Stable Diffusion original paper
% Citations: 5816
@inproceedings{stable_diffusion,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10684--10695},
  year={2022}
}

% GAN Text-to-image synthesis
% Citations: 3718
@inproceedings{reed2016generative,
  title={Generative adversarial text to image synthesis},
  author={Reed, Scott and Akata, Zeynep and Yan, Xinchen and Logeswaran, Lajanugen and Schiele, Bernt and Lee, Honglak},
  booktitle={International conference on machine learning},
  pages={1060--1069},
  year={2016},
  organization={PMLR}
}

% OpenAI Paper: Image synthesis with text conditioning
% Citations: 3640
@article{ramesh2022hierarchical,
  title={Hierarchical text-conditional image generation with clip latents},
  author={Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  journal={arXiv preprint arXiv:2204.06125},
  volume={1},
  number={2},
  pages={3},
  year={2022}
}

% Original paper about diffusion models
% Citations: 3554
@inproceedings{diffusion_models,
  title={Deep unsupervised learning using nonequilibrium thermodynamics},
  author={Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya},
  booktitle={International conference on machine learning},
  pages={2256--2265},
  year={2015},
  organization={PMLR}
}

% Image synthesis
% Citations: 661
@inproceedings{shin2018medical,
  title={Medical image synthesis for data augmentation and anonymization using generative adversarial networks},
  author={Shin, Hoo-Chang and Tenenholtz, Neil A and Rogers, Jameson K and Schwarz, Christopher G and Senjem, Matthew L and Gunter, Jeffrey L and Andriole, Katherine P and Michalski, Mark},
  booktitle={Simulation and Synthesis in Medical Imaging: Third International Workshop, SASHIMI 2018, Held in Conjunction with MICCAI 2018, Granada, Spain, September 16, 2018, Proceedings 3},
  pages={1--11},
  year={2018},
  organization={Springer}
}

% Google paper: Image synthesis: CascadedDPM
% Citations: 643
@article{ho2022cascaded,
  title={Cascaded diffusion models for high fidelity image generation},
  author={Ho, Jonathan and Saharia, Chitwan and Chan, William and Fleet, David J and Norouzi, Mohammad and Salimans, Tim},
  journal={The Journal of Machine Learning Research},
  volume={23},
  number={1},
  pages={2249--2281},
  year={2022},
  publisher={JMLRORG}
}

% GAN Image synthesis: VQ-GAN
% Citations: 207
@article{yu2021vector,
  title={Vector-quantized image modeling with improved vqgan},
  author={Yu, Jiahui and Li, Xin and Koh, Jing Yu and Zhang, Han and Pang, Ruoming and Qin, James and Ku, Alexander and Xu, Yuanzhong and Baldridge, Jason and Wu, Yonghui},
  journal={arXiv preprint arXiv:2110.04627},
  year={2021}
}

% Survey of Image Generation
% Citations: 197
@article{jiao2019survey,
  title={A survey on the new generation of deep learning in image processing},
  author={Jiao, Licheng and Zhao, Jin},
  journal={Ieee Access},
  volume={7},
  pages={172231--172263},
  year={2019},
  publisher={IEEE}
}

% Image synthesis survey
% Citations: 48
@inproceedings{tsirikoglou2020survey,
  title={A survey of image synthesis methods for visual machine learning},
  author={Tsirikoglou, Apostolia and Eilertsen, Gabriel and Unger, Jonas},
  booktitle={Computer Graphics Forum},
  volume={39},
  number={6},
  pages={426--451},
  year={2020},
  organization={Wiley Online Library}
}

% Comprehensive, good survey about GANs
% Citations: 48
@article{dash2023review,
  title={A review of Generative Adversarial Networks (GANs) and its applications in a wide variety of disciplines: From Medical to Remote Sensing},
  author={Dash, Ankan and Ye, Junyi and Wang, Guiling},
  journal={IEEE Access},
  year={2023},
  publisher={IEEE}
}

% DPM made slim
% Citations: 38
@inproceedings{yang2023diffusion,
  title={Diffusion probabilistic model made slim},
  author={Yang, Xingyi and Zhou, Daquan and Feng, Jiashi and Wang, Xinchao},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={22552--22562},
  year={2023}
}

% DPM Image Synthesis (KOALA)
% Citations: 1
% Source: https://huggingface.co/etri-vilab/koala-700m-llava-cap
@article{lee2023koala,
  title={KOALA: Self-attention matters in knowledge distillation of latent diffusion models for memory-efficient and fast image synthesis},
  author={Lee, Youngwan and Park, Kwanyong and Cho, Yoorhim and Lee, Yong-Ju and Hwang, Sung Ju},
  journal={arXiv preprint arXiv:2312.04005},
  year={2023}
}

% Stable Diffusion 3 Official Paper
% Citations: 0
% Source: https://stabilityai-public-packages.s3.us-west-2.amazonaws.com/Stable+Diffusion+3+Paper.pdf
% Website: https://stability.ai/news/stable-diffusion-3-research-paper

















% Vision Transformer
% Citations: 30781
@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

% WGAN
% Citations: 15367
@inproceedings{arjovsky2017wasserstein,
  title={Wasserstein generative adversarial networks},
  author={Arjovsky, Martin and Chintala, Soumith and Bottou, L{\'e}on},
  booktitle={International conference on machine learning},
  pages={214--223},
  year={2017},
  organization={PMLR}
}

% OpenAI DALL-E paper
% Citations: 3329
@inproceedings{dalle,
  title={Zero-shot text-to-image generation},
  author={Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  booktitle={International conference on machine learning},
  pages={8821--8831},
  year={2021},
  organization={Pmlr}
}

% Stanford, optimize DDPMs by 10x to 50x
% Citations: 2704
@article{song2020denoising,
  title={Denoising diffusion implicit models},
  author={Song, Jiaming and Meng, Chenlin and Ermon, Stefano},
  journal={arXiv preprint arXiv:2010.02502},
  year={2020}
}

% Score-based generative models (SGMs)
% Citations: 2209
@article{song2019generative,
  title={Generative modeling by estimating gradients of the data distribution},
  author={Song, Yang and Ermon, Stefano},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

% OpenAI improved learning objective of DDPM
% Citations: 1788
@inproceedings{nichol2021improved,
  title={Improved denoising diffusion probabilistic models},
  author={Nichol, Alexander Quinn and Dhariwal, Prafulla},
  booktitle={International conference on machine learning},
  pages={8162--8171},
  year={2021},
  organization={PMLR}
}

% Stochastic differential equations (Score SDEs)
% Citations: 633
@article{karras2022elucidating,
  title={Elucidating the design space of diffusion-based generative models},
  author={Karras, Tero and Aittala, Miika and Aila, Timo and Laine, Samuli},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={26565--26577},
  year={2022}
}

% DPM Survey
% Citations: 543
@article{yang2023diffusion_survey,
  title={Diffusion models: A comprehensive survey of methods and applications},
  author={Yang, Ling and Zhang, Zhilong and Song, Yang and Hong, Shenda and Xu, Runsheng and Zhao, Yue and Zhang, Wentao and Cui, Bin and Yang, Ming-Hsuan},
  journal={ACM Computing Surveys},
  volume={56},
  number={4},
  pages={1--39},
  year={2023},
  publisher={ACM New York, NY, USA}
}

% DPM Survey
% Citations: 445
@article{croitoru2023diffusion,
  title={Diffusion models in vision: A survey},
  author={Croitoru, Florinel-Alin and Hondru, Vlad and Ionescu, Radu Tudor and Shah, Mubarak},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2023},
  publisher={IEEE}
}

% Explanation for VAEs
% Citations: 186
@article{girin2020dynamical,
  title={Dynamical variational autoencoders: A comprehensive review},
  author={Girin, Laurent and Leglaive, Simon and Bie, Xiaoyu and Diard, Julien and Hueber, Thomas and Alameda-Pineda, Xavier},
  journal={arXiv preprint arXiv:2008.12595},
  year={2020}
}

% Google paper explaining DPM
% Citations: 155
@article{luo2022understanding,
  title={Understanding diffusion models: A unified perspective},
  author={Luo, Calvin},
  journal={arXiv preprint arXiv:2208.11970},
  year={2022}
}

% Survey paper about DPMs
% Citations: 133
@article{cao2024survey,
  title={A survey on generative diffusion models},
  author={Cao, Hanqun and Tan, Cheng and Gao, Zhangyang and Xu, Yilun and Chen, Guangyong and Heng, Pheng-Ann and Li, Stan Z},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  year={2024},
  publisher={IEEE}
}

% AnimatedDiff
% Citations: 95
@article{guo2023animatediff,
  title={Animatediff: Animate your personalized text-to-image diffusion models without specific tuning},
  author={Guo, Yuwei and Yang, Ceyuan and Rao, Anyi and Wang, Yaohui and Qiao, Yu and Lin, Dahua and Dai, Bo},
  journal={arXiv preprint arXiv:2307.04725},
  year={2023}
}

% DDPMs Noise schedulers
% Citations: 63
@article{chen2023importance,
  title={On the importance of noise scheduling for diffusion models},
  author={Chen, Ting},
  journal={arXiv preprint arXiv:2301.10972},
  year={2023}
}

% VAE Survey
% Citations: 27
@article{asperti2021survey,
  title={A survey on variational autoencoders from a green AI perspective},
  author={Asperti, Andrea and Evangelista, Davide and Loli Piccolomini, Elena},
  journal={SN Computer Science},
  volume={2},
  number={4},
  pages={301},
  year={2021},
  publisher={Springer}
}

% Patches: Patch-based Object-centric Video Transformer (POVT)
% Citations: 2
@article{yan2022patch,
  title={Patch-based Object-centric Transformers for Efficient Video Generation},
  author={Yan, Wilson and Okumura, Ryo and James, Stephen and Abbeel, Pieter},
  journal={arXiv preprint arXiv:2206.04003},
  year={2022}
}

% Genie
% Citations: 0
@article{bruce2024genie,
  title={Genie: Generative Interactive Environments},
  author={Bruce, Jake and Dennis, Michael and Edwards, Ashley and Parker-Holder, Jack and Shi, Yuge and Hughes, Edward and Lai, Matthew and Mavalankar, Aditi and Steigerwald, Richie and Apps, Chris and others},
  journal={arXiv preprint arXiv:2402.15391},
  year={2024}
}


% Midjourney website
@misc{midjourney-website,
  title = {Midjourney website},
  url = {https://www.midjourney.com/home}
}

@misc{dk-divergence-math-explanation,
    title = {KL Divergence video explanation},
    url = {https://www.youtube.com/watch?v=9_eZHt2qJs4}
}









% Predict future images from video
% Citations: 2198
@article{mathieu2015deep,
  title={Deep multi-scale video prediction beyond mean square error},
  author={Mathieu, Michael and Couprie, Camille and LeCun, Yann},
  journal={arXiv preprint arXiv:1511.05440},
  year={2015}
}

% GAN Video sythesis: VGAN (VideoGAN)
% Citations: 1653
@article{vondrick2016generating,
  title={Generating videos with scene dynamics},
  author={Vondrick, Carl and Pirsiavash, Hamed and Torralba, Antonio},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

% Video synthesis: vid2vid
% Citations: 1082
@article{wang2018video,
  title={Video-to-video synthesis},
  author={Wang, Ting-Chun and Liu, Ming-Yu and Zhu, Jun-Yan and Liu, Guilin and Tao, Andrew and Kautz, Jan and Catanzaro, Bryan},
  journal={arXiv preprint arXiv:1808.06601},
  year={2018}
}

% Video synthesis: TGAN (Temporal GAN)
% Citations: 622
@inproceedings{saito2017temporal,
  title={Temporal generative adversarial nets with singular value clipping},
  author={Saito, Masaki and Matsumoto, Eiichi and Saito, Shunta},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2830--2839},
  year={2017}
}

% Imagen: DPM Video synthesis
% Citations: 606
@article{ho2022imagen,
  title={Imagen video: High definition video generation with diffusion models},
  author={Ho, Jonathan and Chan, William and Saharia, Chitwan and Whang, Jay and Gao, Ruiqi and Gritsenko, Alexey and Kingma, Diederik P and Poole, Ben and Norouzi, Mohammad and Fleet, David J and others},
  journal={arXiv preprint arXiv:2210.02303},
  year={2022}
}

% Meta AI: text to video generation
% Citations: 544
@article{singer2022make,
  title={Make-a-video: Text-to-video generation without text-video data},
  author={Singer, Uriel and Polyak, Adam and Hayes, Thomas and Yin, Xi and An, Jie and Zhang, Songyang and Hu, Qiyuan and Yang, Harry and Ashual, Oron and Gafni, Oran and others},
  journal={arXiv preprint arXiv:2209.14792},
  year={2022}
}

% LDM Video Synthesis: Video-LDM
% Citations: 266
@inproceedings{blattmann2023align,
  title={Align your latents: High-resolution video synthesis with latent diffusion models},
  author={Blattmann, Andreas and Rombach, Robin and Ling, Huan and Dockhorn, Tim and Kim, Seung Wook and Fidler, Sanja and Kreis, Karsten},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={22563--22575},
  year={2023}
}

% Video synthesis
% Citations: 223
@inproceedings{li2018video,
  title={Video generation from text},
  author={Li, Yitong and Min, Martin and Shen, Dinghan and Carlson, David and Carin, Lawrence},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  number={1},
  year={2018}
}

% GAN Video synthesis: MoCoGAN-HD
% Citations: 138
@article{tian2021good,
  title={A good image generator is what you need for high-resolution video synthesis},
  author={Tian, Yu and Ren, Jian and Chai, Menglei and Olszewski, Kyle and Peng, Xi and Metaxas, Dimitris N and Tulyakov, Sergey},
  journal={arXiv preprint arXiv:2104.15069},
  year={2021}
}

% DVD-GAN
% Citations: 192
% Source: https://paperswithcode.com/method/dvd-gan
@article{clark2019adversarial,
  title={Adversarial video generation on complex datasets},
  author={Clark, Aidan and Donahue, Jeff and Simonyan, Karen},
  journal={arXiv preprint arXiv:1907.06571},
  year={2019}
}

% DPM Video survey
% Citations: 132
@article{yang2023diffusion_video,
  title={Diffusion probabilistic modeling for video generation},
  author={Yang, Ruihan and Srivastava, Prakhar and Mandt, Stephan},
  journal={Entropy},
  volume={25},
  number={10},
  pages={1469},
  year={2023},
  publisher={MDPI}
}

% GAN Video synthesis: TFGAN
% Citations: 92
@inproceedings{balaji2019conditional,
  title={Conditional GAN with Discriminative Filter Generation for Text-to-Video Synthesis.},
  author={Balaji, Yogesh and Min, Martin Renqiang and Bai, Bing and Chellappa, Rama and Graf, Hans Peter},
  booktitle={IJCAI},
  volume={1},
  number={2019},
  pages={2},
  year={2019}
}

% GAN Video generation survey
% Citations: 72
@article{aldausari2022video,
  title={Video generative adversarial networks: a review},
  author={Aldausari, Nuha and Sowmya, Arcot and Marcus, Nadine and Mohammadi, Gelareh},
  journal={ACM Computing Surveys (CSUR)},
  volume={55},
  number={2},
  pages={1--25},
  year={2022},
  publisher={ACM New York, NY}
}

% StabilityAI: Stable Diffusion for Video Generation
% Citations: 32
@article{blattmann2023stable,
  title={Stable video diffusion: Scaling latent video diffusion models to large datasets},
  author={Blattmann, Andreas and Dockhorn, Tim and Kulal, Sumith and Mendelevitch, Daniel and Kilian, Maciej and Lorenz, Dominik and Levi, Yam and English, Zion and Voleti, Vikram and Letts, Adam and others},
  journal={arXiv preprint arXiv:2311.15127},
  year={2023}
}

% DPM Video synthesis: IDF-Video
% Citations: 13
@article{gu2023reuse,
  title={Reuse and diffuse: Iterative denoising for text-to-video generation},
  author={Gu, Jiaxi and Wang, Shicong and Zhao, Haoyu and Lu, Tianyi and Zhang, Xing and Wu, Zuxuan and Xu, Songcen and Zhang, Wei and Jiang, Yu-Gang and Xu, Hang},
  journal={arXiv preprint arXiv:2309.03549},
  year={2023}
}






% Google paper: Video synthesis using DPM
% Paper: https://openreview.net/pdf?id=BBelR2NdDZ5











% VQGAN
% Citations: 1984
@inproceedings{vqgan,
  title={Taming transformers for high-resolution image synthesis},
  author={Esser, Patrick and Rombach, Robin and Ommer, Bjorn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={12873--12883},
  year={2021},
}

% Imagen
% Citations: 3837
@article{imagen,
  title={Photorealistic text-to-image diffusion models with deep language understanding},
  author={Saharia, Chitwan and Chan, William and Saxena, Saurabh and Li, Lala and Whang, Jay and Denton, Emily L and Ghasemipour, Kamyar and Gontijo Lopes, Raphael and Karagol Ayan, Burcu and Salimans, Tim and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={36479--36494},
  year={2022}
}

% Video-LDM
% Citations: 471
@inproceedings{video_ldm,
  title={Align your latents: High-resolution video synthesis with latent diffusion models},
  author={Blattmann, Andreas and Rombach, Robin and Ling, Huan and Dockhorn, Tim and Kim, Seung Wook and Fidler, Sanja and Kreis, Karsten},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={22563--22575},
  year={2023}
}

% Stable Video Diffusion
% Citations: 199
@article{stable_video_diffusion,
  title={Stable video diffusion: Scaling latent video diffusion models to large datasets},
  author={Blattmann, Andreas and Dockhorn, Tim and Kulal, Sumith and Mendelevitch, Daniel and Kilian, Maciej and Lorenz, Dominik and Levi, Yam and English, Zion and Voleti, Vikram and Letts, Adam and others},
  journal={arXiv preprint arXiv:2311.15127},
  year={2023}
}

% Make-a-Video
% Citations: 778
@article{make_a_video,
  title={Make-a-video: Text-to-video generation without text-video data},
  author={Singer, Uriel and Polyak, Adam and Hayes, Thomas and Yin, Xi and An, Jie and Zhang, Songyang and Hu, Qiyuan and Yang, Harry and Ashual, Oron and Gafni, Oran and others},
  journal={arXiv preprint arXiv:2209.14792},
  year={2022}
}

% Sora website
@misc{sora_website,
  title        = {Sora by OpenAI website},
  year         = {2024},
  url = {https://openai.com/index/sora}
}

% Transformers
% Citations: 123714
@article{transformer,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

% VQ-VAE
% Citations: 3886
@article{vqvae,
  title={Neural discrete representation learning},
  author={Van Den Oord, Aaron and Vinyals, Oriol and others},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

% GAN
% Citations: 69508
@article{gan,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

% Autoencoders.
% "According to the history provided in Schmidhuber, "Deep learning in neural networks: an overview," Neural Networks (2015), auto-encoders were proposed as a method for unsupervised pre-training in Ballard, "Modular learning in neural networks," Proceedings AAAI (1987)."
% Citations: 22169
@article{autoencoder,
  title={Deep learning in neural networks: An overview},
  author={Schmidhuber, J{\"u}rgen},
  journal={Neural networks},
  volume={61},
  pages={85--117},
  year={2015},
  publisher={Elsevier}
}

% Original 1987 introduction to Autoencoder architecture
% Citations: 595
@inproceedings{autoencoder2,
  title={Modular learning in neural networks},
  author={Ballard, Dana H},
  booktitle={Proceedings of the sixth National conference on Artificial intelligence-Volume 1},
  pages={279--284},
  year={1987}
}

% VAE
% Citations: 33653
@article{vae,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

% CNN introduction
% Citations:  80761
@article{cnn,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group UK London}
}

% VAE + CNN example paper
% Citations: 
@article{vae_cnn_example,
  title={Convolutional variational autoencoder-based feature learning for automatic tea clone recognition},
  author={Zilvan, Vicky and Ramdan, Ade and Heryana, Ana and Krisnandi, Dikdik and Suryawati, Endang and Yuwana, R Sandra and Kusumo, R Budiarianto S and Pardede, Hilman F},
  journal={Journal of King Saud University-Computer and Information Sciences},
  volume={34},
  number={6},
  pages={3332--3342},
  year={2022},
  publisher={Elsevier}
}

@misc{ae_vs_vae,
  title        = {AE v.s. VAE figure source},
  url = {https://vitalflux.com/autoencoder-vs-variational-autoencoder-vae-difference/}
}

@misc{vq_visualization_website,
  title = {Vector quantization visualization, website source},
  url = {https://speechprocessingbook.aalto.fi/Modelling/Vector_quantization_VQ.html}
}

% Autoencoder original paper which wasn't used in machine learning until 2010s
% Citations: 28167
@article{autoencoder_original_paper_1986,
  title={Learning internal representations by error propagation, parallel distributed processing, explorations in the microstructure of cognition, ed. de rumelhart and j. mcclelland. vol. 1. 1986},
  author={Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J},
  journal={Biometrika},
  volume={71},
  number={599-607},
  pages={6},
  year={1986}
}

% Autoencoder paper from 2006 that introduced dimensionality reduction
% Citations: 22963
@article{autoencoder_2006_paper,
  title={Reducing the dimensionality of data with neural networks},
  author={Hinton, Geoffrey E and Salakhutdinov, Ruslan R},
  journal={science},
  volume={313},
  number={5786},
  pages={504--507},
  year={2006},
  publisher={American Association for the Advancement of Science}
}

% PixelCNN
% Citations: 2758
@inproceedings{van2016pixel,
  title={Pixel recurrent neural networks},
  author={Van Den Oord, A{\"a}ron and Kalchbrenner, Nal and Kavukcuoglu, Koray},
  booktitle={International conference on machine learning},
  pages={1747--1756},
  year={2016},
  organization={PMLR}
}

% Very interesting read. Explains why the round function is not differentiable, which is important for the VQ-VAE model, since in VQ we 'round' embeddings to nearest codebook vectors.
@misc{why_round_function_is_not_differentiable,
  title = {Why the round function is not differentiable},
  url = {https://ai.stackexchange.com/questions/26770/in-vq-vae-code-what-does-this-line-of-code-signify}
}

% GAN mode collapse image source
@misc{gan_mode_collapse_image_source,
  title = {GAN mode-collapse image source},
  url = {https://pub.towardsai.net/gan-mode-collapse-explanation-fa5f9124ee73}
}

