
In stable diffusion paper, explain the figure 2.

In stable diffusion paper, verify this statement:
"In Stable Diffusion, the authors used the text encoder from CLIP. % TODO: Verify, read the paper."

In diffusion models, redo the UNet backbone. We need more professional stuff.

======================================================
In Stable diffusion we have multiple previous works, which includes:

Maybe explain CLIP more?
Maybe explain ViT (Vision Transformer)?
Maybe explain Word2Vec?
Maybe explain ResNet?
======================================================

Explain in VQ-GAN paper how they researchers converted conditional information, such as depth map, semantic masks, text, and so on, to tokens. How did images converted to tokens?

Maybe the minGPT encoder converted images to tokens automatically?

Also, you need to explain in the paper what it means that the researchers had to train a new VQ-GAN model for each conditional type.



======================================
* Explain layer normalization in cross-attention layers
* Explain cross-attention layers?
* What are residual blocks?
======================================

After explaining the Imagen ResNetBlock, DBlock, UBlock, explain before that: GroupNorm, swish, Conv blocks (convolution).


In video synthesis answer the question: what is spatio-temporal convolutional?