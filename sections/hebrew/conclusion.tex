\begin{hebrew}
\begin{RTL}

\section*{סיכום} % Unnumbered section after appendix
% \addcontentsline{toc}{section}{\texthebrew{סיכום}}


העבודה בוחנת התקדמות אחרונה בטכניקות למידה עמוקה לחילול תמונות ווידאו,  
תוך התמקדות במעבר מהתחום הבוגר של חילול תמונות לאתגרים החדשים של חילול וידאו.  
בחנו מודלים בסיסיים, כולל \LR{VAEs}, \LR{GANs}, ומודלים מבוססי \LR{DMs}.  
חקרנו את המודלים החדישים ביותר כמו \LR{VQ-GAN}, \LR{LDM}, ו-\LR{Imagen} לחילול תמונות, והמודלים
\LR{Video-LDM}, \LR{Imagen-Video}, \LR{Make-a-Video} לחילול וידאו.  
להלן סיכום קצר של המודלים שנדונו:




\begin{itemize}
    \item \textbf{\LR{VQ-VAEs}}: מודלים הסתברותיים המשתמשים במשתנים חבויים לשחזור תמונות, 
    המאפשרים אינטרפולציה חלקה במרחב החבוי. 
    \LR{VQ-VAE} משפר את \LR{VAEs} על ידי הכנסת קוונטיזציה וקטורית, 
    אשר מבצעת דיסקרטיזציה למרחב החבוי ומקלה על למידת התפלגות ודגימה בצורה יעילה יותר.

    \item \textbf{\LR{GANs}}: מודלים אדברסריים הלומדים את התפלגות הנתונים על ידי אימון של מחולל שמייצר דגימות ריאליסטיות, 
    ו-"מבחין" שמבחין בין דגימות אמיתיות למזויפות. עם זאת, \LR{GANs} סובלים מאי-יציבות בזמן האימון בעקבות פונקציית האובדן האדברסרית,
    מה שמוביל לקריסת מודים ובעיות התכנסות. כתוצאה מכך, השימוש בהם ירד עם עליית שיטות מבוססות דיפוזיה.

    \item \textbf{\LR{Stable Diffusion}}: מודל הסתברותי הלומד את התפלגות הנתונים על ידי הוספת רעש בצורה איטרטיבית לנתונים, 
    ואז לומד לבטל את הרעש בהדרגה. \LR{Stable Diffusion} מהווה בסיס לרוב מודלי חילול התמונות והוידאו בזכות היציבות 
    שלו והתוצרים האיכותיים שהוא מפיק.

    \item \textbf{\LR{Imagen}}: \LR{Imagen} משתמש בטרנספורמרים לצורך חילול תמונות מטקסט (\LR{T2I}), ומשלב את היתרונות שלהם 
    עם מודלים דיפוזיים מדורגים וטכניקות של סופר-רזולוציה כדי להגיע לתמונה ברזולוציה גבוהה.
    ראינו שככל שיש יותר פרמטרים בטרנספורמר, כך מדדי האיכות \LR{FID} ו-\LR{CLIP} משתפרים.
\end{itemize}







לאחר מכן אנו מעבירים את ההתמקדות לחילול וידאו, הבנוי על מודלים מבוססי חילול תמונה:





\begin{itemize}
    \item \textbf{\LR{VideoGPT}}: מודל מבוסס טרנספורמר היוצר סרטונים על ידי חיזוי פריימים עתידיים בהתבסס על פריימים קודמים. הוא משתמש ב-VQ-VAE כדי לפעול במרחב החבוי במקום במרחב הפיקסלים, מה שיעיל יותר מבחינה חישובית.
    
    \item \textbf{\LR{Video-LDM}}: אשר משתמש במודל \LR{T2I LDM} מאומן מראש,
    ומרחיב אותו לחילול וידיאו על ידי הקפאת שכבות המרחב והוספת שכבות קשב זמני וקונבולוציות תלת-ממדיות על מנת להתאים את המודל לנתוני וידיאו.
    הוא פועל במרחב החבוי, ומשלב "מבחין" של \LR{GAN}
    כדי לשפר את הקוהרנטיות הזמנית.

    \item \textbf{\LR{Imagen-Video}}: מודל \LR{T2V} המבוסס על העבודה הקודמת של \LR{Imagen}, ומרחיב אותו לחילול וידאו.
    הוא עושה שימוש בדיפוזיה מדורגת עם שבעה מודלים מבוססי דיפוזיה לשיפור הרזולוציה המרחבית והזמנית.

    \item \textbf{\LR{Make-a-Video}}: מודל המבוסס על העבודה של \LR{DALL-E 2}, 
    אשר עושה שימוש בקונבולוציות פסאודו-3D
    ובשכבות פסאודו-זמניות
    כדי לאזן בין יעילות חישובית לאיכות הוידיאו,
    ובכך מתמודד עם העלות הגבוהה של קשב זמני מלא וקונבולוציות תלת-ממדיות.


\end{itemize}





אתגר מרכזי במודלים של \LR{T2V} הוא העלות הגבוהה של האימון, כאשר חלק מהמשימות דורשות שימוש במאות מעבדים גרפיים.
למרות מאמצים רבים להוזיל את עלות האימון, גודל מערך הנתונים  והמורכבות הזמנית נותרים אתגר מרכזי.
דחיסה יעילה יותר של ייצוגי וידאו, חקר של בלוקים מרחביים-זמניים יעילים, והאצה של זמני האימון והחיזוי הם חיוניים לעתיד
של חילול וידאו ארוך.

שיטות אוטורגרסיביות לחילול וידאו ארוך סובלות מהצטברות שגיאות~\cite{ouyang2024flexifilm},
מה שמוביל לאיכות ירודה יותר בפריימים המאוחרים. בנוסף, רוב מודלי חילול וידאו כיום מסוגלים להפיק
רק סרטונים באורך של פחות מ-10 שניות.

לסיכום, המעבר ממודלים לחילול תמונה למודלים לחילול וידאו ממחיש את ההתפתחות של יכולות הבינה המלאכותית בתחום.
בעוד שמודלים לחילול תמונה הגיעו לרמת בשלות עם תוצרים מציאותיים מאוד, חילול וידאו נותר תחום הדורש גישות חדשניות בכדי להתמודדות עם קוהרנטיות זמנית ואתגרים חישוביים.





\end{RTL}
\end{hebrew}





% \begin{itemize}
%     \item \textbf{VQ-VAEs}: מודלים הסתברותיים המשתמשים במשתנים סמויים לשחזורי תמונה מובנים, ומאפשרים אינטרפולציה חלקה במרחב הסמוי. VQ-VAE משפר את VAEs על ידי הצגת קוונטיזציה וקטורית, המבצעת דיסקרטיזציה של המרחב הסמוי כדי לאפשר למידת פריור ויצירת דגימות יעילות יותר.
%    
%     \item \textbf{GANs}: מודלים יריביים הלומדים את התפלגות הנתונים על ידי אימון גנרטור לייצר דגימות ריאליסטיות ודיסקרימינטור להבחין בין דגימות אמיתיות לדגימות שנוצרו. עם זאת, GANs סובלים מחוסר יציבות במהלך האימון עקב פונקציית הפסד יריבית, מה שמוביל לקריסת מודלים ובעיות התכנסות. כתוצאה מכך, השימוש בהם פחת עם עליית שיטות מבוססות דיפוזיה.
%    
%     \item \textbf{Stable Diffusion}: מודל הסתברותי הלומד את התפלגות הנתונים על ידי החלת רעש באופן איטרטיבי על הנתונים ולאחר מכן לומד להסיר רעש באופן איטרטיבי. Stable Diffusion הוא לרוב הבסיס לרוב מודלי יצירת התמונות והווידאו בגלל יציבותו ותפוקות באיכות גבוהה.
%    
%     \item \textbf{Imagen}: Imagen ממנף טרנספורמרים ליצירת טקסט לתמונה (T2I), ומשלב את חוזקותיהם עם מודלי דיפוזיה מדורגים וטכניקות סופר-רזולוציה כדי להשיג ביצועים חדישים. הם הראו שככל שיש יותר פרמטרים בטרנספורמר, כך ציוני ההערכה FID ו-CLIP טובים יותר.
% \end{itemize}

% לאחר מכן אנו מעבירים את המיקוד לסינתזת וידאו, הבנויה על טכניקות מבוססות תמונה כדי להתמודד עם אתגרים זמניים:

% \begin{itemize}
% \item \textbf{VideoGPT}: מודל מבוסס טרנספורמר היוצר סרטונים על ידי חיזוי פריימים עתידיים בהתבסס על פריימים קודמים. הוא משתמש ב-VQ-VAE כדי לפעול במרחב הסמוי במקום במרחב הפיקסלים, מה שיעיל יותר מבחינה חישובית.

% \item \textbf{Video-LDM}: לוקח מודל LDM T2I שאומן מראש לתחום הווידאו על ידי הקפאת השכבות המרחביות והוספת שכבות של תשומת לב זמנית וקונבולוציה תלת-ממדית על מנת לבצע כוונון עדין לנתוני וידאו. הוא פועל במרחב הסמוי ומשלב דיסקרימינטור GAN כדי לשפר את הקוהרנטיות הזמנית של הווידאו שנוצר.

% \item \textbf{Imagen-Video}: מודל T2V המבוסס על עבודתו הקודמת של Imagen, הוא מרחיב את Imagen ליצירת וידאו, תוך שימוש במסגרת דיפוזיה מדורגת עם שבעה מודלים מבוססי דיפוזיה כדי לשפר את הרזולוציה המרחבית והזמנית.

% \item \textbf{Make-a-Video}: מודל המבוסס על עבודתו של DALL-E 2, המשתמש בקונבולוציות פסאודו-תלת-ממדיות ותשומת לב פסאודו-זמנית כדי לאזן בין יעילות חישובית לאיכות גנרטיבית, ובכך מתמודד עם העלות הגבוהה של תשומת לב זמנית מלאה וקונבולוציות תלת-ממדיות.
% \end{itemize}

% אתגר גדול במודלי T2V הוא עלות האימון הכבדה הקשורה למודלי T2V, כאשר חלק מהמשימות דורשות שימוש במאות GPUs. למרות מאמצים רבים להפחית את עלות האימון, הן גודל מערך הנתונים והן המורכבות הזמנית נותרו דאגה קריטית. דחיסה יעילה יותר של ייצוגי וידאו, חקר בלוקים מרחביים-זמניים יעילים והאצת זמני אימון והסקה חיוניים לעתיד סינתזת וידאו ארוך.

% שיטות אוטורגרסיביות ליצירת סרטונים ארוכים סובלות מהצטברות שגיאות \cite{ouyang2024flexifilm}, מה שמוביל לאיכות ירודה יותר בפריימים מאוחרים יותר. יתר על כן, רוב מודלי יצירת הווידאו כיום יכולים לייצר רק סרטונים קצרים מ-10 שניות.

% לסיכום, ההתקדמות ממודלים של יצירת תמונות למודלים של יצירת וידאו ממחישה את היכולות המתפתחות של AI גנרטיבי. בעוד שמודלים של סינתזת תמונות הגיעו לרמת בגרות עם פלט ריאליסטי ביותר, סינתזת וידאו נותרה חזית הדורשת גישות חדשניות כדי להתמודד עם קוהרנטיות זמנית ואתגרים חישוביים.


